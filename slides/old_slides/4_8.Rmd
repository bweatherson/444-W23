---
title: "444 Lecture 4.8 - Expected Value"
author: "Brian Weatherson"
mainfont: SF Pro Rounded
output:
  beamer_presentation:
    md_extensions: +link_attributes+fenced_divs
    keep_tex: yes
    latex_engine: xelatex
    includes:
      in_header: 
        - 444-beamer-header.tex
        - extra-space.tex
        - kableextra-dependencies.tex
mathfont: STIX Two Math
mainfontoptions: BoldFont = SF Pro Rounded Semibold
---

```{r, include=FALSE}
source("kableformat.R")
```
## Plan

- In this lecture we'll do a very quick introduction to the idea of expected value.

## Associated Reading

Still chapter 5, though we're really not going page by page through this chapter.

## Random Variables

- A **random variable**  is simply a variable that takes different numerical values in different states. 
- In other words, it is a function from possibilities to numbers. 
- It need not be 'random' in any familiar sense.
- The function from possible situations to the value of 2 + 2 in that situation is a random variable, albeit a constant one.
- It's just a slightly confusing term for any variable that takes different, numerical, values in different situations.

## Labels

- Typically, random variables are denoted by capital letters. 
- So we might have a random variable $X$ whose value is the age of the next President of the United States, and his or her inauguration. 
- Or we might have a random variable $Y$ that is the number of children you will have in your lifetime. 
- Basically any mapping from possibilities to numbers can be a random variable. 

## An Example

- You've asked each of your friends who will win the Lakers v Clippers game.
- 12 said the Lakers will win.
- 7 said the Clippers will win. \pause
- Then we can let $X$ be a random variable measuring the number of your friends who correctly predicted the result of the game.

\begin{equation*}
X = 
	\begin{cases}
		12,& \text{if Lakers win} ,\\ 
		7,& \text{if Clippers win} .
	\end{cases}
\end{equation*}

## Expected Value

- Given a random variable $X$ and a probability function $Pr$, we can work out the **expected value** of that random variable with respect to that probability function. 
- Intuitively, the expected value of $X$ is a weighted average of the possible values of $X$, where the weights are given by the probability (according to $Pr$) of each value coming about. 

## Calculating Expected Value

- More formally, we work out the expected value of $X$ this way. 
- For each possibility, we multiply the value of $X$ in that case by the probability of the possibility obtaining. 
- Then we sum the numbers we've got, and the result is the expected value of $X$. 
- We'll write the expected value of $X$ as $Exp(X)$. 

## Back to the Example

- So if the probability that the Lakers win is 0.7, and the probability that the Clippers win is 0.3, then

\begin{align*}
Exp(X) &= 12 \times 0.7 + 7 \times 0.3 \\
 &= 8.4 + 2.1 \\
 &= 10.5
\end{align*} 

## Notes

1. The expected value of $X$ isn't in any sense the value that we expect $X$ to take. It's more like an average.
2. If this kind of situation recurs a lot, you would expect the long run average value $X$ takes to be roundabout the expected value.
3. That's a better way of conceptualising what expected values are.

## Summing Up

The standard theory of decisions under uncertainty requires three conceptual innovations.

1. Utility, understood as a measure of how well things are for the decider, and defined in a way such that ratios of differences are meaningful.
2. Probability, understood as measuring the likelihood of classes of outcomes.
3. Expected value, understood as something generated by multiplying probabilities of an outcome by the value of the random variable in that outcome.

## For Next Time

- We will start looking at how to use these tools to analyse games that we couldn't analyse with purely ordinal utility