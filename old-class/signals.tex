% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  11pt,
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmainfont[Scale=MatchLowercase]{Merriweather}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Signaling Games},
  pdfauthor={Brian Weatherson},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1.5in]{geometry}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage[italic]{mathastext}
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{Signaling Games}
\author{Brian Weatherson}
\date{}

\begin{document}
\maketitle

\setstretch{1.15}
\hypertarget{overview}{%
\section{Overview}\label{overview}}

Here is the basic idea of a signaling game.

\begin{itemize}
\tightlist
\item
  There are two players, a sender and a receiver.
\item
  Nature reveals some information to sender. (Or, if you want to make
  the game symmetric, nature chooses one of the two players to reveal
  information to.)
\item
  Sometimes (especially in econonomic applications) we'll call this
  sender's \textbf{type}.
\item
  Sender sends a signal that receiver can see.
\item
  Receiver chooses an action that has a payoff to each player.
\end{itemize}

We'll start by considering \textbf{cooperative} signaling games. These
are games where the players get the same payoff in every situation.
Intuitively, they are ones where the players want to share information
because they are in a joint venture.

To use a famous example, consider Robert Newman, the sexton of the Old
North Church in Boston during the Revolutionary War. Part of his job (as
a revolutionary) was to keep watch for what the Regulars were doing, and
put signals in the window of the church to signal what they were doing.
As the poem says, the signal was ``One if by land, two if by sea''. That
is, he'd put out one lamp if they were coming by land, two if they were
coming by sea. (Actually water; actually the Charles river. But that's
not as poetic.) The other revolutionaries would then take suitable
action.

So here Newman is the sender. Nature (well actually the British army)
has revealed some information to him. (Inadvertently in this case.)
Other people don't know this information. But they do know the signal he
sends; they can see the number of lamps in the window. And they have a
plan for what to do with each thing they see.

Now in reality, the plan they have is a good one. That's because they
have coordinated in advance on what to do. But what if they can't
coordinate? The game in this loose form has any number of Nash
equilibria.

\begin{itemize}
\tightlist
\item
  It has \textbf{separating equilibria} where the townsfolk take
  different actions on seeing the different signals, and things work
  well for hearers and sender.
\item
  It has \textbf{pooling equilibria} where Newman puts up the same
  signal come what may, and the townsfolk do the same thing no matter
  what he does.
\item
  And it has \textbf{babbling equilibia} where Newman chooses randomly
  what to do, and the townsfolk ignore him.
\end{itemize}

But only the separating equilibria are evolutionarily stable (we haven't
discussed this notion, so trust me on this one). There are two of these
- we could have had one if by sea, two if by land. But apart from these
two Nash equilibria, the other Nash equilibria are not evolutionarily
stable.

This matters for two big debates

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What is the relationship between human language and convention?
\item
  How do signaling systems evolve in non-human animals without
  agreement, or in most cases the capacity to do anything like make an
  agreement, as to what the signals will mean?
\end{enumerate}

These are variants of the same question. How do you ever get a signaling
system started? The answer being implicitly suggested here is that you
randomly try a bunch of different strategies for navigating the world,
keep the ones that work and not the ones that don't work (either
intentionally or through natural selection), and eventually you'll end
up signaling.

\hypertarget{cooperative-signaling}{%
\section{Cooperative signaling}\label{cooperative-signaling}}

\hypertarget{simple-cases}{%
\subsection{Simple Cases}\label{simple-cases}}

Our basic signaling game is a 2-by-2-by-2 game. (A lot of these notes
draws on two papers by Simon Huttegger and collaborations:
\href{https://www.pnas.org/content/111/Supplement_3/10873}{Some dynamics
of signaling games}, and
\href{https://faculty.sites.uci.edu/shuttegg/files/2011/03/Hutteggeral2009.pdf}{Evolutionary
dynamics of Lewis signaling games: signaling systems vs.~partial
pooling}.) It has

\begin{itemize}
\tightlist
\item
  2 possible states of the world, one of which is revealed to sender.
\item
  2 possible messages that sender can transmit.
\item
  2 possible actions for receiver to take upon receipt.
\end{itemize}

Intuitively for now, we're interested in situations where one of the
actions is best in one state of the world, and the other is best in the
other state of the world. (And for now we're dealing with cooperative
games, so it's `best' for both players.)

It's worth thinking about how little capacity two things need to be in
order to be able to play this game. Sender just needs the capacity to
differentially respond to some feature of the world. It needs all the
intelligence of a key on a keyboard. (Not the fancy circuitry the key is
connected to - literally the key itself, which is pressure sensitive.)
And receiver doesn't need much more than that. As long as it can
reliably respond to two distinct signals, and those responses could if
needed be distinct, you're good to play this game.

The last thing you need to get an evolutionary story going is that the
things playing the game are subject to evolutionary pressures. That does
rule out things like keys on keyboards, but it doesn't rule out very
much in the natural world. Lots of things are subject to evolutionary
pressures.

Let's add one last thing to the setup. The two states are more or less
equally probable. That isn't always the case, but it will sometimes be
the case at least.

Given that minimal setup, the philosopher of biology Brian Skyrms showed
that, with probability almost 1, one of the separating equilibria for
the signaling game will arise. That is, signaling will eventually
happen. I don't know if this is actually the story of how signaling
arose, but it seems plausible. (I certainly don't know a better story.)

The problem is that as soon as you get away from this very special case,
then the mathematical results aren't so neat. If the two states are not
equally probable, then plenty of plausible models end up converging to
no signal being sent, and the `receiver' acting as if the more probable
state has obtained.

If it is a 3-by-3-by-3 game, then some plausible models converge to a
`partially pooling equilibrium'. Here is how Huttegger et al describe
one such partial pooling equilibrium

\begin{quote}
Consider a \ldots{} signaling game with {[}three states{]}, where the
sender always sends signal 1 in both states 1 and 2, and who in state 3
sometimes sends signal 2 and sometimes sends signal 3. Pair this sender
with a receiver, who does act 3 in response to both signals 2 and 3, and
who upon receiving signal 1 sometimes does act 1 and sometimes act 2, as
shown in Fig. 1. In this equilibrium, information about state 3 is
transmitted perfectly, but states 1 and 2 are ``pooled''.
\end{quote}

What they show is that under some common models for how populations
evolve, sometimes that is what the population evolves to. It isn't
common (it was 4.7\% of the time on one of their models), but it
happens. But if you allow more mutations into the model, this tends to
go away, and the pure signaling equilibrium becomes (yet) more likely to
evolve.

But still, if the neat story becomes less neat with just the move from 2
states to 3 states, it becomes a little worrying what it's like for the
messy real world.

\hypertarget{more-states-than-signals}{%
\subsection{More States than Signals}\label{more-states-than-signals}}

Let's drop the assumption that there are as many messages as states. In
particular, let's think about how to manage the 4-by-2-by-4 game. That's
a game where there are

\begin{itemize}
\tightlist
\item
  4 possible states of the world.
\item
  2 possible messages that can be sent.
\item
  4 possible actions to be taken.
\end{itemize}

Intuitively, what should we want to have happen here?

You might think at first the answer will be, ``Assign one message to two
of the states, and the other message to the other two, and then we'll be
done.'' But it's a bit more complicated than that. Imagine, for example,
that the states are equiprobable, and these are the payoffs. (I'll just
list one, because it's a cooperative game still.)

\begin{longtable}[]{@{}ccccc@{}}
\toprule
& S1 & S2 & S3 & S4 \\
\midrule
\endhead
A1 & 3 & 2 & 1 & 0 \\
A2 & 2 & 3 & 2 & 1 \\
A3 & 1 & 2 & 3 & 2 \\
A4 & 0 & 1 & 2 & 3 \\
\bottomrule
\end{longtable}

Then it is really important that you have one signal for S1/S2, and
another signal for S3/S4. That will have an average payoff of 2.5.
(Question for readers: Why?) And no other messaging system will have as
high a payoff. For instance, if you have one signal for S2/S3 and
another for S1/S4, then the average payoff will be just 1.75. (Again,
it's worth thinking about why.)

So we want signaling systems where like states get similar signals, not
ones where you use a common signal for S1 and S4. Happily, that is
mostly what we see in real-world signaling systems.

But you don't always want to divide things up two ways. Imagine that
this was the payoff table, and again you have just two possible signals.

\begin{longtable}[]{@{}ccccc@{}}
\toprule
& S1 & S2 & S3 & S4 \\
\midrule
\endhead
A1 & 8 & 0 & 0 & 0 \\
A2 & 0 & 2 & 1 & 0 \\
A3 & 0 & 1 & 2 & 1 \\
A4 & 0 & 0 & 1 & 2 \\
\bottomrule
\end{longtable}

The optimal signaling strategy is to use one signal for S1, and the
other for S2/S3/S4. Question: How should hearer respond to these
signals? Question: What's the expected payoff of these signals? We want
our signals to mark practically salient differences in the world. Again,
it is arguable that this is what we find.

In game theory we typically assume that everyone knows the underlying
probability distribution, and the underlying payoff structure. In the
real world, that's not always the case. Let's imagine that people don't
exactly know the payoffs for various actions, and they don't exactly
know the probability distribution over the states. But they do know that
a speaker has a limited number of signals, and is choosing to send a
signal that is optimised to their (i.e., the speaker's) beliefs about
the probabilities and the payoffs. What will happen?

Well, arguably what will happen is that we'll get a signal that is
somewhat \textbf{vague}. In the real world, when you hear someone
described as `tall', or `rich', or `smart', it is clear that they are
being described as being towards the upper end of the
height/wealth/intelligence spectrum. But how close to the top must they
be for this description to be right? It seems that you can be a
perfectly competent speaker of English and not really know. One recent
hypothesis (developed most extensively by Cailin O'Connor at UC Irvine)
is that vagueness arises because players in the signaling game don't
know exactly the parameters of the game they are playing. And the
optimal strategy, i.e., what states you pick out by your signal, is
dependent on the precise values of these parameters. There has been a
lot of work in philosophy and linguistics about what vague terms mean,
but a lot of it treats vagueness as some kind of defect of the language,
as if it's weird why it is even there. This is a very interesting
proposal for why we would naturally have ended up with vague language.

\hypertarget{david-lewis}{%
\subsection{David Lewis}\label{david-lewis}}

A lot of the work on this topic nowadays is done by economists and,
especially, biologists. But it turns out that the origin of the work is
in the early work by the most influential Anglophone philosopher of the
late 20th century, David Lewis. Lewis was interested in the following
puzzle.

On the one hand, it seems that languages are in some way conventional
systems. It isn't a rule of nature that `dog' will be the word for
canines. After all, if it was a law, then it would hold in Paris as well
as in London, and it doesn't. So it looks like it must be some kind of
social arrangement that produces language - what else could it be?

On the other hand, it looks like it couldn't really be a social
arrangement. After all, arrangements have to be made, and they are
typically made in language. So if language is a convention, it must come
after this arrangement was made. And that's impossible, since the
arrangement requires language.

Lewis argued that this second argument, about the impossibility of
formulating the agreement prior to language, was no good. He argued that
conventions don't need to be anything like agreements. Rather, they can
be equilibrium solutions to coordination games. All it takes for there
to be a convention is that people play their part in an equilibrium, and
they do so because it is in their self-interest to do this given that
the equilibrium exists. The causal history of the equilibrium is
irrelevant - it might have been a pure accident when it arose, but once
it comes into place, it is a convention if people follow it because they
have reason to follow it as long as everyone else does.

As well as this somewhat reductive account of what a convention is,
Lewis popularised the 2-by-2-by-2 signaling game, as a model for how we
might think about situations where these conventions come about. I'm not
sure if he was the first to do this. (The work of Lewis's I'm talking
about is in his PhD thesis, that became his 1969 book \emph{Convention},
so what I'm not sure about is how much these games were talked about
prior to 1969.) Lewis explicitly draws on the work by the economist
Thomas Schelling, and Schelling talked about other coordination games.
But in the current literature (or at least the philosophy part of it!)
the credit normally goes to Lewis.

\hypertarget{grounds-for-scepticism}{%
\subsection{Grounds for Scepticism}\label{grounds-for-scepticism}}

All that said, I'm a little sceptical that these general pictures about
signaling can tell us much about the development of human language. The
picture is that language is a solution to a coordination game, and that
people play it because, I guess, they are good at detecting and
continuing with solutions to coordination games. If that's right, then
we have to assume that humans are good at either:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Computing the optimal solutions to games like these; or
\item
  Detecting and following regular social practices that are socially
  beneficial.
\end{enumerate}

And while plenty of humans are actually good at these things, a lot of
humans are not.

But, and this is the really surprising thing, humans are unbelievably
good at picking up the language in their immediate vicinity. It's not
true that 100\% of humans develop competence in the local language, but
it's stunningly close to 100\%. Totally deaf people are an exception,
and people with very severe learning disabilities are sometimes
exceptions as well, but it's striking how few exceptions there are.
Let's say, conservatively, that 99\% of humans end up picking up the
local language - at least to a level where one can get by. (I'm talking
about spoken language here - for most of human history a small
percentage of the population could read and write - but almost all can
talk.)

It's worth thinking about what a bizarre fact this is. Try to think of
any other practice that's as intellectually demanding as carrying out a
conversation in the local language, and ask what percentage of the
population are able to carry it out. Or think of any other beneficial
social practice, and ask what percentage of the population go along with
it. The answers will be well under 99\%.

Of course, a lot of people are far from optimal users of language. But
what I mean that the vast majority of humans can do is (a) parse
utterances using common words in the local dialect, and (b) produce
sentences that don't involve gratuitous grammatical violations. By
grammar here, I don't mean Strunk \& White rules. I mean that you just
don't see vast numbers of humans producing sentences like ``I are
happy'', or ``You am tired''. And it's really staggering how good people
get at parsing the local language. Think how much study of Japanese it
would take to be as good at processing everyday utterances in Japanese
as virtually any three-year-old in Japan. Or how much French you'd have
to study to be as good at correctly gendering the household furniture as
pretty much any four-year-old in Paris. These are hard problems, and
over 99\% of kids figure them out somehow.

So I don't think we understand language in virtue of applying our
general intelligence, or our general sociablility, to a coordination
problem. We know what people are like when they apply general
intelligence, or general sociability, and failures are really frequent.
But failures at picking up the language, and conforming to its general
rules, are really rare. This has suggested to many people that language
must be associated with a special part of the brain, one that is
designed to let us understand and produce sentences of a local language.
(This idea, that language is associated with an innate, special purpose,
system is often associated with the work of Noam Chomsky, though it's
now a very widely held view.)

Now maybe we could still apply these game theoretic considerations `one
level up'. Maybe the reason we evolved a special purpose language system
is because having such a system is an evolutionarily stable strategy. On
this picture, it's not that we as individuals are trying (and
succeeding) to solve a coordination problem. Rather, it's that we are
`programmed' to get to the solution instinctively, and the reason we are
programmed this way rather than some other way is that this programming
is part of a stable equilibrium. Maybe - but we should remember that
language is very special, and that it is unlikely that general purpose
reasoning will tell us just how it works.

\hypertarget{non-coperative-signaling}{%
\section{Non-Coperative Signaling}\label{non-coperative-signaling}}

\hypertarget{basic-game}{%
\subsection{Basic Game}\label{basic-game}}

Let's drop the assumption that sender and receiver have the same
interests. We won't assume that their interests are totally in conflict
- this isn't zero-sum. But they might be in conflict. There are lots of
ways this could happen, but here is the one we'll start with.

\begin{itemize}
\tightlist
\item
  Two states of the world - sender knows them, receiver doesn't. Call
  them `High' and `Low'. (Or H/L.) Assume for now that High is
  marginally more probable than Low.
\item
  Two possible signals/messages that sender can send - call them
  `Difficult' and `Easy' for reasons that we will get to. (Or D/E).
\item
  Two possible actions receiver can take - call them Risky and Safe (Or
  R/S).
\end{itemize}

In words, here are the payoffs:

\begin{itemize}
\tightlist
\item
  Sender pays 0 to perform Easy, but a cost \(c > 0\) to perform
  Difficult. This is subtracted from whatever their ultimate payout is.
  (We will complicate this clause in a bit.)
\item
  Receiver gets a payout of 0 for doing Safe.
\item
  If Receiver plays Risky, they get 1 if High, and -1 if Low.
\item
  Sender gets 1 (minus whatever cost they incurred at round 1) if Risky,
  and 0 (minus whatever cost they incurred at round 1) if Low.
\end{itemize}

In table form, here are the payouts. First, here are the payouts for
High.

\begin{longtable}[]{@{}rcc@{}}
\toprule
& Risky & Safe \\
\midrule
\endhead
Difficult & \(1-c, 1\) & \(-c, 0\) \\
Easy & \(1, 1\) & \(0, 0\) \\
\bottomrule
\end{longtable}

Now, here are the payouts for Low.

\begin{longtable}[]{@{}rcc@{}}
\toprule
& Risky & Safe \\
\midrule
\endhead
Difficult & \(1-c, -1\) & \(-c, 0\) \\
Easy & \(1, -1\) & \(0, 0\) \\
\bottomrule
\end{longtable}

Let's try to work through what the equilibria are for different values
of \(c\).

\begin{itemize}
\tightlist
\item
  First, assume \(c < 1\).
\item
  Assume that Receiver will do different things if Difficult or Easy.
\item
  Then Sender will do whatever makes Receiver do Risky, whether it is D
  or E. So no separating equilibrium.
\item
  Now assume Receiver will do the same thing if Difficult or Easy.
\item
  Then of course Sender will do Easy and get that payout, whatever it
  is.
\item
  Again, no separating equilibrium.
\end{itemize}

What does produce a separating equilibrium is if the cost is different
in High and Low. Change the `penalty' for playing Difficult so that in
High, the penalty is \(c_1 < 1\), and in Low, the penalty is
\(c_2 > 1\). Now we get the following equilibrium.

\begin{itemize}
\tightlist
\item
  Sender does Difficult if High, Easy if Low.
\item
  Receiver does Risky if Difficult, Safe if Easy.
\end{itemize}

(Aside: You also get one other really weird equilibrium where

\begin{itemize}
\tightlist
\item
  Sender always does Easy.
\item
  Receiver does Risky if Easy, Safe if Difficult.
\end{itemize}

This is mathematically interesting - and hence interesting to me -
because it is not just a Nash equilibrium and subgame perfect, but also
satisfies all the extra criteria developed in chapters 11 and 12 to rule
out intuitively absurd equilibria like this one. But it is hard to see
how it has any real-world relevance - it doesn't look like it could
naturally evolve, for example - and I'll ignore it from here on.)

So we get a separating equilibrium. And maybe we get a model of some
fascinating real-world things. In most of these cases, Sender has
something like a continuum of choices from Easy to Difficult, and
Receiver has a continuum from Risky to Safe. But it arguably helps to
look at the binary case first, and maybe we can generalise that to the
real-world example.

Two caveats before we start the examples.

In practice, biologists seem happy to use this procedure - think about
the binary model and then generalise to the continuous case - while
economists prefer to start with the continuous case. My intuitions are
normally with the economists, but here I'm acting like a biologist.

And these are possible models of what we see. In every case, I'm going
to eventually raise worries for the model. But I want to have them on
the table.

\hypertarget{example-one-tail-feathers}{%
\subsection{Example One:
Tail-Feathers}\label{example-one-tail-feathers}}

Male peacocks have very colorful tails. On the face of it, this doesn't
look like it serves any purpose in either collecting food or avoiding
becoming food. (Quite the opposite in fact.) But maybe we should think
of it as a move in a signaling game.

\begin{itemize}
\tightlist
\item
  Sender is the male, choosing whether to have a normal tail (Easy) or a
  colourful tail (Difficult). `Choosing' here is misleading - it's less
  misleading to say their genes choose.
\item
  Sender is either Strong (that's High) or Weak (that's Low).
\item
  It's resource-intensive to produce (and preserve) a colorful tail, but
  it's more costly for Weak than for Strong peacocks.
\item
  Receiver is a female, choosing a mate. They prefer Strong to Weak -
  since they want better genes for their children. (Again, it's hard to
  say this is what the individual female wants - better to say there are
  evolutionary advantages to acting as if that's what she wants.)
\item
  So perhaps an equilibrium is Strong have colorful tails, Weak don't,
  and females who have a choice prefer males with colorful tails.
\end{itemize}

\hypertarget{example-two-stotting}{%
\subsection{Example Two: Stotting}\label{example-two-stotting}}

Stotting is where a quadruped leaps into the air, with legs relatively
stiff. Stotting is common among young animals in various species. But
the really odd thing is that among some gazelles, it only happens when a
predator is nearby. And why they do this is a bit of a mystery. It
doesn't seem that efficient as a means of propulsion. And revealing
one's location this dramatically doesn't seem like a good tactic in
predator avoidance. But maybe it's a move in a signaling game. In this
game, the payouts are slightly changed. The gazelle is the sender, and
the predator is the receiver, and the predator's payoffs are going to be
different from the standard game.

\begin{itemize}
\tightlist
\item
  High in this case is that the gazelle is strong (High means things are
  good from the predator's perspective.) Low is that the gazelle is
  weak.
\item
  Stotting is Difficult; Not-stotting is Easy.
\item
  Chasing this particular gazelle is Risky; leaving it is Safe.
\item
  But here we change the payoffs. Here receiver/predator gets -1 for
  doing Risky in High, and 1 for doing Risky in Safe. Otherwise the game
  is the same.
\end{itemize}

Again, there is a separating equilibria.

\begin{itemize}
\tightlist
\item
  Gazelle stotts if and only if they are strong.
\item
  Predator chases if and only if they don't see stotting.
\end{itemize}

And so there is an advantage to stotting - you don't get chased - even
though holding fixed the state of the world and the behavior of the
predator, stotting is a cost with no benefit. It doesn't help you get
away - it helps the predator not choose to attack.

\hypertarget{example-three-university}{%
\subsection{Example Three: University}\label{example-three-university}}

We'll deal with this in more detail in the next section, but here is the
basic idea.

\begin{itemize}
\tightlist
\item
  Employers pay graduates much more (really a lot more) than non-grads.
\item
  Employers aren't dumb (I hope) so they must be more valuable.
\item
  But it's kind of hard to see how what we do here adds much economic
  value. What businesses make more profit by having people who really
  understand modal metaphysics rather than having people who don't?
\item
  So maybe education is a signal.
\item
  A crude model: college is more fun the smarter you are.
\item
  So finishing college is less costly for smarter people, and they make
  better employees.
\end{itemize}

In terms we've used so far

\begin{itemize}
\tightlist
\item
  Sender is the college graduate. They are either High - i.e., valuable
  to employers, or Low - not so valuable.
\item
  Receiver is the high wage employer. They can do the Risky thing - hire
  this person - or the Safe thing - not hire them.
\item
  Going to college is Difficult. But - and this is the crucial thing -
  on this model it is more Difficult for Low than for High. All those
  calculus classes are really unpleasant. But they are more unpleasant
  for Low - so much so that \(c_2 > 1\).
\item
  So the separating equilibrium is High goes to college and Low hits the
  beach/workforce. Then high-wage employers hire college graduates only.
\item
  And all this happens even though college is a pure cost to everyone
  who goes there. Employer doesn't get any reward for hiring graduates -
  they get same reward for hiring High grads as High non-grads. And
  holding all else fixed, every young person is better off skipping
  college than going.
\end{itemize}

\hypertarget{the-spence-model}{%
\section{The Spence Model}\label{the-spence-model}}

\hypertarget{background}{%
\subsection{Background}\label{background}}

According to recent-ish research from the San Francisco Federal Reserve,
here are the average hourly wages for Americans by educational level as
of 2015. (I don't think the numbers have changed much since; if anything
the pandemic made the differences larger.) I've also added a column for
what percentage of the workforce each of these groups are. Source:
\url{https://www.frbsf.org/economic-research/files/wp2016-17.pdf}

\begin{longtable}[]{@{}ccc@{}}
\toprule
Education & Wage & Ratio \\
\midrule
\endhead
No degree & \$13.56 & 7.7\% \\
High school degree & \$17.98 & 25.6\% \\
Some college & \$21.59 & 27.8\% \\
Undergrad degree & \$30.93 & 24.7\% \\
Graduate degree & \$39.48 & 14.3\% \\
\bottomrule
\end{longtable}

What could explain the fact that college graduates earn almost 75\% more
per hour than high school graduates? There are two obvious
possibilities.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Universities impart lots of valuable skills, and employers are
  rationally responding to this value we add by paying more for more
  valuable employees.
\item
  It's a selection effect - the people who come to college were more
  valuable before they came here, and employees are rationally
  responding to that underlying fact.
\end{enumerate}

These aren't exclusive, but let's pretend for now we're going to assume
one of them is decisive, and we're trying to figure out which it is.
There are two things missing in explanation 2.

First, why do all these smart people choose to go to college? On the one
hand, it is mostly fun. On the other hand, it's expensive, and there are
a lot of other fun things you could do with the money. If it's all about
the climbing walls, you could join the fanciest gym in the country for a
fraction of the cost. If it's about meeting new people, you could go
backpacking around Europe. If it's about intellectual stimulation, you
could take a gap year or four and spend your days reading and listening
to educational podcasts.

Second, why do employers look for college degrees as the signal of who
they will pay high wages to? Why don't they simply ask to see your offer
letters? If it's just a selection effect, then you can see who has been
selected in as soon as the offer letters go out - and that should be
enough to make employers happy. But it's not - they want degrees not
just offer letters. (This seems really obvious, but I think it's kind of
a striking fact about the modern world, and one that doesn't get enough
attention in a lot of debates.)

\hypertarget{the-basic-model}{%
\subsection{The Basic Model}\label{the-basic-model}}

So we need a model that explains why we don't see, for example, valuable
employees taking their offer letters and backpacking around Europe with
Kindles and podcasts for their spare time. Spence's signaling model
provides such an explanation.

\begin{itemize}
\tightlist
\item
  Sender is the college graduate. They are either High - i.e., valuable
  to employers, or Low - not so valuable.
\item
  Receiver is the high wage employer. They can do the Risky thing - hire
  this person - or the Safe thing - not hire them.
\item
  Going to college is Difficult. But - and this is the crucial thing -
  on this model it is more Difficult for Low than for High. All those
  calculus classes are really unpleasant. But they are more unpleasant
  for Low - so much so that \(c_2 > 1\).
\item
  So the separating equilibrium is High goes to college and Low hits the
  beach/workforce. Then high-wage employers hire college graduates only.
\item
  And all this happens even though college is a pure cost to everyone
  who goes there. Employer doesn't get any reward for hiring graduates -
  they get same reward for hiring High grads as High non-grads. And
  holding all else fixed, every young person is better off skipping
  college than going.
\end{itemize}

\hypertarget{evaluating-spence}{%
\subsection{Evaluating Spence}\label{evaluating-spence}}

The Spence model is meant to explain a few distinct weird features of
the market in higher education. But it faces questions of its own.
Indeed, any signaling explanation faces a few questions.

First, why does receiver take the signal seriously? Why don't they think
that some senders are sending dishonest signals. The answer is supposed
to be that somehow the signal is too costly for people to send
dishonestly. But this is a big call.

Second, why does sender send the signal? Note that there are a couple of
distinct questions here. In general, why questions are contrastive, and
here you really need to think about the relevant contrasts. Why do
senders (i.e., students) send this signal rather than no signal at all?
Answer - it pays really well. That's a good answer! But why do senders
send this signal rather than some other signal? If you want to signal
intelligence and perserverance, a good SAT score and a year in the
military, or working as a volunteer for a good charity, are much better
signals. (And cheaper.) And why hasn't the market arranged some more
effective signal? Maybe a one year `degree' that involves like 80 hour
work weeks, and is basically impossible to send dishonestly. You
wouldn't learn much that way, but by hypothesis you don't learn much
under the current system. And this would be financially cheaper, and a
more meaningful signal.

Third, and this really is the most crucial one, why don't non-senders
send? Maybe they can't; we'll turn to that option next. But otherwise,
you need to make those classes really incredibly unpleasant to explain
passing up a 75\% pay raise.

\hypertarget{personal-observation}{%
\subsection{Personal Observation}\label{personal-observation}}

I'll answer these questions myself in a bit, but think about how you
would answer these questions based on your personal experience of
college.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  What aspects of this model seem to resemble the world you (as in
  literally you personally) find yourself in? (I mean found yourself in
  before February 2020 - Spence isn't committed to the model working in
  a pandemic.)
\item
  What aspects of it seem to differ from the world in significant ways?
\item
  What empirical data would make you think this model was right in some
  important way?
\item
  What empirical data would make you think this model was wrong in some
  important way?
\end{enumerate}

\hypertarget{my-observations}{%
\subsection{My Observations}\label{my-observations}}

\emph{What aspects of this model seem to resemble the world you (as in
literally you personally) find yourself in?}

The basic structure of the model seems plausible. It isn't obvious how
what we do here makes you a more valuable employee. It might make you
better citizens, but employers don't care about that. And calculus class
really is less pleasant for people who won't be as valuable to
employers. Even if they won't use calculus, we are setting up challenges
where the cost of completion at least somewhat correlates with value to
employers.

\emph{What aspects of it seem to differ from the world in significant
ways?}

The wage premium is so high that it's hard to believe \(c_2 > 1\). The
same is true for the tail feathers and stotting examples. The payouts to
Difficult are really really high, and calculus class isn't that
differentially unpleasant.

\emph{What empirical data would make you think this model was right in
some important way?}

Restricting things to data I know exist - one thing that supports the
model is the `sheepskin effect'. If you divide the `some college' group
by how much college they got, the skills hypotheis would predict that
the more college you did, the higher your wage premium. That might be
approximately true. But it would also predict that if you're one course
from graduation, you would get 95\% or more of the wage premium. And
that's wildly false. People who are one course short of graduation get
paid massively less than people who graduate. And this is very hard to
explain on anything other than a signaling model of some kind.

\emph{What empirical data would make you think this model was wrong in
some important way?}

One thing that's trouble for the model is that the wage premium is
really high among older workers. To make that work, you need one of a
few implausible things. One possibility is that you need employers who
are so unobservant that they can't tell the valuable workers from the
not valuable workers after years and years of work, so they still have
to rely on degrees as a signaling device. Or maybe the things that make
college incredibly unpleasant for the people employers want to avoid are
deep facts about people, and the characteristics that made college a
non-worthwhile expense at age 19 still make them less employable at age
49. I don't know, this doesn't seem super likely to me.

\hypertarget{another-hypothesis}{%
\subsection{Another Hypothesis}\label{another-hypothesis}}

So far we've assumed everyone can do Difficult or Easy, but it is more
costly for Low than High. Maybe we should drop that assumption. Here is
another kind of signaling model that we could consider. (The point here
is that there are more signaling hypotheses about the value of education
than the Spence model.)

\begin{itemize}
\tightlist
\item
  The basic structure of sender, receiver, signal and receiver actions
  are the same.
\item
  Now the cost of Difficult is the same for High and Low.
\item
  But now Sender isn't in full control of their actions.
\item
  If they choose Easy, then Easy happens.
\item
  But if they choose Difficult, then they have to pay the cost \(c\),
  but what happens, and what Receiver sees, is Difficult with
  probability \(p\), and Easy with probability \(1-p\).
\item
  And the probability is high for High and low for Low.
\item
  Again, we get a separating equilibrium.
\item
  Receiver does Risky if they see High, and Safe if they see Low. (Or
  the other way around in the stotting game.)
\item
  And the expected payouts are such that High should take the chance and
  do Difficult, while Low should not.
\item
  At the extreme, the probability of success is 1 for High and 0 for
  Low, but the model works even with much more balanced probabilities.
\end{itemize}

This is sometimes called the \textbf{Honest signaling} model, or the
\textbf{Indexical signaling} model, as opposed to the \textbf{Handicap
Principle} model we started with.

\hypertarget{mixing-the-hypotheses}{%
\subsection{Mixing the Hypotheses}\label{mixing-the-hypotheses}}

Maybe for some Senders, they have a choice about what costs to incur,
with the more costs they incur increasing their probability of success.

\begin{itemize}
\tightlist
\item
  This is easier to see in the college case. Imagine a person who has
  the skills to finish a college degree, but doesn't have the skills to
  finish while holding down a 40 hour job, and it would be really costly
  to give up the 40 hour job.
\item
  For that person, going to college and keeping the job might not be
  worth it - it would be like doing the low-probability Difficult
  signal, which usually just results in paying a cost and getting no
  return.
\item
  But going to college and giving up the job might not be worth it
  either. If the cost \(c\) isn't just the tuition cost, but the money
  foresaken from the job, and perhaps the interest on the loans taken
  out to cover that money, then perhaps the cost is higher than the
  premium.
\end{itemize}

In general, we might want to be a little sceptical that there is clean
line between cases where a player chooses not to send a costly signal,
and cases where that player doesn't have the ability to (reliably) send
that signal. Maybe the signal success probability is a function of the
costs incurred, and there is no level of costs they can justify
spending.

\hypertarget{for-more-information}{%
\subsection{For More information}\label{for-more-information}}

For stats on the college wage premium over time, see

\begin{itemize}
\tightlist
\item
  \url{https://fredblog.stlouisfed.org/2018/07/is-college-still-worth-it/}
\end{itemize}

For information on the college wealth premium, plus stats on the
demographics of both the wage premium and the wealth premium, see

\begin{itemize}
\tightlist
\item
  \url{https://www.stlouisfed.org/~/media/files/pdfs/hfs/is-college-worth-it/emmons_symposium.pdf?la=en}
\end{itemize}

\end{document}
